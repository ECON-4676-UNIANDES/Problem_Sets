\documentclass[12pt,onecolumn,A4]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%          				PACKAGES  				              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[margin=1.5in]{geometry}
\usepackage{authblk}
%\usepackage[latin1]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage{placeins}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage{a4wide,graphicx,color}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage[table]{xcolor}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{dcolumn}
\usepackage{color,soul}
\usepackage{threeparttable}
\usepackage[capposition=top]{floatrow}
\usepackage[labelsep=period]{caption}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{lscape}
\usepackage{pdflscape}
\usepackage{multicol}
\usepackage[bottom]{footmisc}
\setlength\footnotemargin{5pt}
\usepackage{longtable}
\usepackage{chronosys}
\catcode`\@=11
\def\chron@selectmonth#1{\ifcase#1\or Jan\or Feb\or Mar\or Apr\or May\or Jun\or Jul\or Aug\or Sep\or Oct\or Nov\or Dec\fi}

%% BibTeX settings
\usepackage{natbib}
\bibliographystyle{apalike}
\bibpunct{(}{)}{,}{a}{,}{,}

%% markup commands for code/software
\let\code=\texttt
\let\pkg=\textbf
\let\proglang=\textsf
\newcommand{\file}[1]{`\code{#1}'}
\newcommand{\email}[1]{\href{mailto:#1}{\normalfont\texttt{#1}}}
\urlstyle{same}

%% paragraph formatting
\renewcommand{\baselinestretch}{1}

%% \usepackage{Sweave} is essentially
\RequirePackage[T1]{fontenc}
\RequirePackage{ae,fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}

% Defines columns for tables
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


\usepackage{bbm}
\usepackage{enumitem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     			TITLE, AUTHORS AND DATE    			  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Problem Set 3}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Econ 4676: Big Data and Machine Learning for Applied Economics}
\author{{\bf Due Date}: There are two deadlines for this problem set. The usual deadline for the document is November 19 at 11:00 am. The deadline for predictions is November 18 at 8:00 pm. }
\date{}
%\href{https://github.com/ECON-4676-UNIANDES}{ECON-4676}}

\begin{document}
\maketitle

\section{Theory Exercises}

\begin{enumerate}
  \item {\it LDA vs QDA}. I showed in class where the term ``linear'' comes from LDA. However, I skipped steps in Lecture 19 slide 18. 
  \begin{enumerate}
    \item Show the complete steps from odds ratio and equal variance assumption that allows reaching a linear function for the odds ratio. 
    \item Lift the equal variance assumption, and show that you reach a quadratic function. 
    \item Generate some simulated data and plot the decision boundaries for both classifiers. 
  \end{enumerate}
  \item {\it Binary Response Online Updating}. The problem is simple but yet complicated. Online updating is essential because it breaks the storage barrier and helps with computation. Assume that a new observation arrives, and instead of refitting the entire model, you want to update your binary model estimates. Show that the contribution made by the observation $i$ to the likelihood function is
\begin{align}
l(y,\beta) = \sum_{i=1}^N \left( y_i log F(x'_i\beta) + (1-y_i) log F(1-x'_i\beta)  \right))
\end{align}
  is globally concave with respect to $\beta$ if the function $F$ is such that $F(-x)=1-F(x)$, and if it's derivative $f$, and it's second derivative $f'$ satisfy the condition
  \begin{align}
  f'(x)F(x)-f^2(x)<0
  \end{align}
  for all real finite $x$. Show that this condition is satisfied by the logistic function $\Lambda(x)=\frac{1}{1+e^{-x}}=\frac{e^{x}}{1+e^{x}}$

  \item {\it Fake it until you make it}. Suppose that you have the following model
  \begin{align}
  y^*_i &= \beta_0 + \beta_1 x_i + u_i \\
  u_i &\sim N(0,1) \\
  x_i &\sim N(0,1)
  \end{align}
  but you observe
  \begin{align}
  y_{i}=\begin{cases}
1 & if\;y_{i}^{*}>0\\
0 & if\;y_{i}^{*}\leq0
\end{cases}
  \end{align}
  \begin{enumerate}
  \item Generate 500 samples of 20 observations of $(x_i,y_i)$:
  \begin{enumerate}
  \item 100 assuming that $\beta_0=0$ and $\beta_1 =1 $
  \item 100 assuming that $\beta_0=1$ and $\beta_1 =1 $
  \item 100 assuming that $\beta_0=-1$ and $\beta_1 =1 $
  \item 100 assuming that $\beta_0=0$ and $\beta_1 =2 $
  \item 100 assuming that $\beta_0=0$ and $\beta_1 =3$
  \end{enumerate}
  
  \item For each of the 500 samples, estimate a Probit model. You'll note that the estimation fails because of perfect classifiers. What proportion of the time does this failure happen?
  \item Why there are more failures in some cases than in others?
  \item Repeat the exercise but now increase the sample size to 40. Is there a change? Can you say something about the effect of the sample size?
  \item Don't forget to set a seed so your results can be replicated.
  \end{enumerate}

  \item {\it Piano piano va lontano}. Suppose you want to minimize the following function 
  \begin{align}
  f(\beta_1,\beta_2)=\frac{1}{2}(\beta_1^2-\beta_2)^2+ \frac{1}{2}(\beta_1-1)^2
  \end{align}
  \begin{enumerate}
    \item Compute the gradients $\frac{\partial f}{\partial \beta_1}$ and $\frac{\partial f}{\partial \beta_2}$
    \item Using gradient descent for the win. Write the following function
    \begin{enumerate}
      \item Give initial values $\beta_1$ and $\beta_2$
      \item Until $f(\beta^i_1,\beta^i_2)$ {\it ``does not change much do''}
      \begin{itemize}
       \item $\beta_1^{i+1} = \beta_1^{i} - \eta \frac{\partial f}{\partial \beta_1}$
       \item $\beta_2^{i+1} = \beta_2^{i} - \eta \frac{\partial f}{\partial \beta_2}$
       \item compute $|f^{i+1}-f^{i}|$
       \item if $|f^{i+1}-f^{i}|<tol$ stop, otherwise continue
       \item $i \leftarrow i+1$
      \end{itemize}
      \item here you need to define the step size $\eta$ and what {\it ``does not change much do''}. 
      \begin{enumerate}
        \item Pick a ``small'' step and a ``big'' step. 
        \item Set a high tolerance rate $(tol)$ and a small tolerance rate to define {\it ``does not change much do''}. 
      \end{enumerate}
      \item Graphically illustrate these results
    \end{enumerate}
  \end{enumerate}
\end{enumerate}



\section{Empirical Problems}

The main objective of these sections is to apply the concepts we learned using ``real" world data. With these, I also expect that you sharpen your data collection and wrangling skills. Finally, you should pay attention to your writing.

I encourage you to turn each of the following two parts of the problem set in a way that resembles paper. As such, I expect graphs, tables, and writing to be as neat as possible. You can write it in Spanish or English, either language is fine. For students in the Ph.D., it would be a good practice to do it in English.

These parts also involve a lot of coding. Please attach your code with your responses or point to your repo. In coding, like in writing, a good coding style is critical for readable code. I encourage you to follow the \href{https://style.tidyverse.org/}{tidyverse style guide}.

{\bf In this problem set, we add a new wrinkle}. I'll base part of your grade on your following Jacob's rubric posted in the course communication channel. The rubric details how to structure the repository and the document. The repo link to create your submission is \url{https://classroom.github.com/g/_k73dlEL}.

\subsection{{\it ``Wars of nations are fought to change maps. But wars of poverty are fought to map change''} M. Ali}

This section was inspired by a recent competition hosted by the world bank: \href{https://www.drivendata.org/competitions/50/worldbank-poverty-prediction/page/97/}{Pover-T Tests: Predicting Poverty}. The idea is to predict poverty in Colombia. As the competition states {\it ``measuring poverty is hard, time consuming, and expensive. By building better models, we can run surveys with fewer, more targeted questions that rapidly and cheaply measure the effectiveness of new policies and interventions. The more accurate our models, the more accurately we can target interventions and iterate on policies, maximizing the impact and cost-effectiveness of these strategies.''} Today this is our objective.

Predictions have to be made at the household level only. Data, however, is provided at the household and individual levels. You can use individual-level information to build extra variables to improve your prediction. You can use the variable \texttt{id} to merge households with individuals. 

A document describing the variables is available in the data folder. You can also check them on the  \href{http://microdatos.dane.gov.co/index.php/catalog/608/datafile/F1#page=F2&tab=data-dictionary}{DANE website}.

The data folder contains four data sets. Training and testing data sets at the household and the individual level. You will note that some variables are missing in the testing data sets. This is by design, to prevent ``cheating'', and make things a bit more challenging. 

The expected output of this section are a document and a \texttt{.csv} file of predictions. 

\begin{enumerate}
	\item  The document should:
	\begin{enumerate}
	\item Explain the data used, and describe the variables in it you are planning on using on your model. Mention if you made any adjustments/transformations. 
	\item Describe the model you used for your final prediction. 
  \begin{enumerate}
    \item You should explain how you reached that model and the variables that you used. 
    \item You should include comparisons to at least 4 other models. You can compare them in terms of ROC, AUC, or in terms of the intended scoring function, i.e., false-positive rates, false-negative rates, and model sparsity. Remember that a portion of the judging depends on the sparsity of your model. 
  \end{enumerate}
	\end{enumerate}
	\item Besides writing up your results, you should submit a \texttt{.csv}. The submission file format is the variable id, and a 0-1 Poor prediction, where 1 denotes Poor and 0 otherwise. An example of how the submission file should look like is in the data folder. I will judge predictions based on false-positive rates, false-negative rates, and the model's sparsity. On presentation day, I will announce the "winning," which will present first and get extra credit. 
\end{enumerate}








\end{document}
